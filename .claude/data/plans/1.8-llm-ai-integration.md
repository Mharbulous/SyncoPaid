# LLM & AI Integration - Implementation Plan

> **TDD Required:** Each task: Write test → RED → Write code → GREEN → Commit

**Goal:** Enable AI-powered categorization and billing narrative generation from activity data.

**Approach:** Create local matter/client database with schema for matching. Integrate LLM API (OpenAI/Anthropic) for activity classification with prompt engineering for billing context. Build review UI with approve/edit workflow. Implement 6-minute billing increment rounding logic.

**Tech Stack:** Python 3.11+, SQLite (matter DB), OpenAI/Anthropic API, existing syncopaid modules (database.py, exporter.py), tkinter/pystray for review UI

---

**Story ID:** 1.8 | **Created:** 2025-12-12 | **Status:** `planned`

---

## Story Context

**Title:** LLM & AI Integration

**Description:** **As a** lawyer reviewing my daily activity log
**I want** AI-powered categorization and billing narrative generation
**So that** I can quickly convert raw activity data into billable time entries with minimal manual effort

**Acceptance Criteria:**
- [ ] Local matter/client database for AI matching
- [ ] LLM API integration for activity classification
- [ ] Automatic billing narrative generation from activity sequences
- [ ] Configurable billing increment rounding (6-minute standard)
- [ ] Review UI for approving/editing AI-generated entries

## Prerequisites

- [ ] venv activated: `venv\Scripts\activate`
- [ ] Baseline tests pass: `python -m pytest -v`
- [ ] LLM API key configured (OpenAI or Anthropic)

## Files Affected

| File | Change | Purpose |
|------|--------|---------|
| `tests/test_matters.py` | Create | Test matter DB operations |
| `src/syncopaid/matters.py` | Create | Matter/client database |
| `tests/test_llm.py` | Create | Test LLM integration |
| `src/syncopaid/llm.py` | Create | LLM API client & prompts |
| `tests/test_billing.py` | Create | Test billing logic |
| `src/syncopaid/billing.py` | Create | Time rounding & narrative generation |
| `tests/test_review_ui.py` | Create | Test review UI logic |
| `src/syncopaid/review_ui.py` | Create | Review/edit interface |
| `src/syncopaid/config.py:15-45` | Modify | Add LLM config defaults |

## TDD Tasks

### Task 1: Matter/Client Database Schema

**Files:** Test: `tests/test_matters.py` | Impl: `src/syncopaid/matters.py`

**RED:** Create test for matter CRUD operations.
```python
def test_create_matter():
    db = MatterDatabase(':memory:')
    matter_id = db.create_matter('Client A', 'Matter 123', 'Estate Planning')
    assert matter_id is not None
    matter = db.get_matter(matter_id)
    assert matter['client_name'] == 'Client A'
    assert matter['matter_code'] == 'Matter 123'
```
Run: `pytest tests/test_matters.py::test_create_matter -v` → Expect: FAILED

**GREEN:** Implement MatterDatabase with SQLite schema.
```python
class MatterDatabase:
    def __init__(self, db_path):
        self.conn = sqlite3.connect(db_path)
        self._create_schema()

    def _create_schema(self):
        self.conn.execute('''
            CREATE TABLE IF NOT EXISTS matters (
                id INTEGER PRIMARY KEY,
                client_name TEXT NOT NULL,
                matter_code TEXT UNIQUE NOT NULL,
                practice_area TEXT,
                created_at TEXT DEFAULT CURRENT_TIMESTAMP
            )
        ''')
```
Run: `pytest tests/test_matters.py::test_create_matter -v` → Expect: PASSED

**COMMIT:** `git add tests/test_matters.py src/syncopaid/matters.py && git commit -m "feat: add matter/client database schema"`

---

### Task 2: LLM API Client

**Files:** Test: `tests/test_llm.py` | Impl: `src/syncopaid/llm.py`

**RED:** Create test for activity classification (mocked API).
```python
@patch('openai.ChatCompletion.create')
def test_classify_activity(mock_api):
    mock_api.return_value = {'choices': [{'message': {'content': '{"matter_code": "Matter 123", "narrative": "Research estate law"}'}}]}
    llm = LLMClient(api_key='test')
    result = llm.classify_activity('Google Chrome - Estate Tax Research')
    assert result['matter_code'] == 'Matter 123'
```
Run: `pytest tests/test_llm.py::test_classify_activity -v` → Expect: FAILED

**GREEN:** Implement LLMClient with OpenAI/Anthropic adapter.
```python
class LLMClient:
    def __init__(self, api_key, provider='openai'):
        self.api_key = api_key
        self.provider = provider

    def classify_activity(self, activity_text):
        prompt = f"Classify this legal work activity: {activity_text}"
        # Call API with prompt engineering
        return parsed_response
```
Run: `pytest tests/test_llm.py::test_classify_activity -v` → Expect: PASSED

**COMMIT:** `git add tests/test_llm.py src/syncopaid/llm.py && git commit -m "feat: add LLM API client for activity classification"`

---

### Task 3: Billing Increment Rounding

**Files:** Test: `tests/test_billing.py` | Impl: `src/syncopaid/billing.py`

**RED:** Create test for 6-minute increment rounding.
```python
def test_round_to_billing_increment():
    assert round_to_increment(5, 6) == 6  # 5 min → 6 min
    assert round_to_increment(7, 6) == 12  # 7 min → 12 min
    assert round_to_increment(120, 6) == 120  # 2 hours exact
```
Run: `pytest tests/test_billing.py::test_round_to_billing_increment -v` → Expect: FAILED

**GREEN:** Implement rounding logic.
```python
def round_to_increment(minutes, increment=6):
    import math
    return math.ceil(minutes / increment) * increment
```
Run: `pytest tests/test_billing.py::test_round_to_increment -v` → Expect: PASSED

**COMMIT:** `git add tests/test_billing.py src/syncopaid/billing.py && git commit -m "feat: add 6-minute billing increment rounding"`

---

### Task 4: Narrative Generation from Activity Sequences

**Files:** Test: `tests/test_billing.py` | Impl: `src/syncopaid/billing.py`

**RED:** Create test for narrative generation from multiple activities.
```python
def test_generate_narrative():
    activities = [
        {'app': 'Chrome', 'title': 'Estate Tax Research'},
        {'app': 'Word', 'title': 'Trust Amendment Draft.docx'}
    ]
    narrative = generate_billing_narrative(activities)
    assert 'estate tax' in narrative.lower()
    assert 'trust amendment' in narrative.lower()
```
Run: `pytest tests/test_billing.py::test_generate_narrative -v` → Expect: FAILED

**GREEN:** Implement narrative aggregation with LLM.
```python
def generate_billing_narrative(activities):
    combined = '; '.join([f"{a['app']}: {a['title']}" for a in activities])
    return llm_client.generate_narrative(combined)
```
Run: `pytest tests/test_billing.py::test_generate_narrative -v` → Expect: PASSED

**COMMIT:** `git add tests/test_billing.py src/syncopaid/billing.py && git commit -m "feat: generate billing narrative from activity sequences"`

---

### Task 5: Review UI for Approve/Edit Workflow

**Files:** Test: `tests/test_review_ui.py` | Impl: `src/syncopaid/review_ui.py`

**RED:** Create test for review UI state management.
```python
def test_review_entry_approval():
    ui = ReviewUI()
    entry = {'matter': 'Matter 123', 'narrative': 'Research', 'time': 0.2}
    ui.load_entry(entry)
    ui.approve()
    assert ui.get_status() == 'approved'
```
Run: `pytest tests/test_review_ui.py::test_review_entry_approval -v` → Expect: FAILED

**GREEN:** Implement ReviewUI with tkinter dialogs.
```python
class ReviewUI:
    def __init__(self):
        self.current_entry = None
        self.status = None

    def load_entry(self, entry):
        self.current_entry = entry

    def approve(self):
        self.status = 'approved'
        # Save to database
```
Run: `pytest tests/test_review_ui.py::test_review_entry_approval -v` → Expect: PASSED

**COMMIT:** `git add tests/test_review_ui.py src/syncopaid/review_ui.py && git commit -m "feat: add review UI for billing entry approval"`

---

### Task 6: Config Defaults for LLM Settings

**Files:** Test: `tests/test_config.py` | Impl: `src/syncopaid/config.py:15-45`

**RED:** Create test for LLM config defaults.
```python
def test_llm_config_defaults():
    config = ConfigManager(':memory:')
    assert config.get('llm_provider') == 'openai'
    assert config.get('billing_increment') == 6
```
Run: `pytest tests/test_config.py::test_llm_config_defaults -v` → Expect: FAILED

**GREEN:** Add LLM settings to DEFAULT_CONFIG.
```python
DEFAULT_CONFIG = {
    # ... existing config ...
    'llm_provider': 'openai',
    'llm_api_key': '',
    'billing_increment': 6,
    'matter_db_path': os.path.join(DATA_DIR, 'matters.db')
}
```
Run: `pytest tests/test_config.py::test_llm_config_defaults -v` → Expect: PASSED

**COMMIT:** `git add tests/test_config.py src/syncopaid/config.py && git commit -m "feat: add LLM configuration defaults"`

---

## Verification

- [ ] All tests pass: `python -m pytest -v`
- [ ] Module tests:
  - [ ] `python -m syncopaid.matters` (verify DB creation)
  - [ ] `python -m syncopaid.llm` (verify API connection with mock)
  - [ ] `python -m syncopaid.billing` (verify rounding logic)
- [ ] Integration test: Export JSON → classify with LLM → generate billing entries → review UI

## Notes

**Edge Cases:**
- Handle LLM API rate limits with retry logic
- Support offline mode (skip AI, manual classification)
- Handle multi-matter activities (e.g., email thread spanning clients)

**Follow-up Work:**
- Matter database import from existing billing system
- Batch processing for historical data
- Training/fine-tuning on user's billing patterns
- Cost tracking for LLM API usage
