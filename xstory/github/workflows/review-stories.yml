name: Daily Story Review

# Run at 3:00 AM PST (11:00 UTC) every day - after verify-stories in DRAIN phase
# Reviews stories in 'reviewing' stage and advances to 'verifying' if passed
on:
  # schedule disabled - manual trigger only
  workflow_dispatch:

concurrency:
  group: daily-story-review
  cancel-in-progress: false

permissions:
  contents: write
  issues: write
  pull-requests: write
  id-token: write

jobs:
  review-stories:
    runs-on: ubuntu-latest
    timeout-minutes: 30

    steps:
      - name: Checkout repository
        uses: actions/checkout@v5
        with:
          fetch-depth: 0  # Full history for git operations

      - name: Run Claude Code to review stories
        id: claude
        uses: anthropics/claude-code-action@v1
        with:
          # GitHub token for repository operations (required for scheduled workflows)
          github_token: ${{ secrets.GITHUB_TOKEN }}

          # Use OAuth token for Max subscription
          claude_code_oauth_token: ${{ secrets.CLAUDE_CODE_OAUTH_TOKEN }}

          # Show full output for debugging
          show_full_output: true

          # Direct prompt mode for scheduled automation (CI-optimized)
          # Transition: reviewing (no hold) → verifying (pass) or reviewing (broken)
          prompt: |
            MODE: Daily Story Review (CI - fully autonomous)

            This workflow reviews stories that had deferrable issues during execution.
            Stories in 'reviewing' stage need code review before advancing to verification.

            ## Step 1: Find Stories Ready for Review

            Query reviewing stories without holds:

            ```python
            python3 << 'QUERY_SCRIPT'
            import sqlite3
            import json

            conn = sqlite3.connect('.claude/data/story-tree.db')
            conn.row_factory = sqlite3.Row

            # Find all reviewing stories without holds
            stories = conn.execute("""
                SELECT id, title, description, notes, project_path
                FROM story_nodes
                WHERE stage = 'reviewing'
                  AND hold_reason IS NULL
                  AND disposition IS NULL
                ORDER BY updated_at ASC
            """).fetchall()

            print(f"Found {len(stories)} story(ies) ready for review:")
            for s in stories:
                print(f"  - {s['id']}: {s['title'][:60]}...")
                if s['notes']:
                    # Show recent notes (last 200 chars)
                    recent = s['notes'][-200:] if len(s['notes']) > 200 else s['notes']
                    print(f"    Notes: ...{recent}")

            result = {
                'count': len(stories),
                'stories': [
                    {
                        'id': s['id'],
                        'title': s['title'],
                        'project_path': s['project_path'],
                        'notes': s['notes']
                    } for s in stories
                ]
            }
            print(json.dumps(result, indent=2))
            conn.close()
            QUERY_SCRIPT
            ```

            If count is 0, output "✓ No stories ready for review" and exit successfully.

            ## Step 2: Review Each Story

            For each story found, perform a code review:

            ### 2a. Analyze Deferred Issues

            Read the story notes to understand what issues were deferred during execution.
            Look for patterns like:
            - "DEFERRED:" notes from execution
            - Code quality issues that were noted but not blocking
            - Test coverage gaps
            - Documentation needs

            ### 2b. Check Code Quality

            If project_path is set, examine the related code:
            - Use Grep to find relevant code files
            - Check if deferred issues have been addressed
            - Look for obvious bugs or issues

            ### 2c. Run Related Tests

            If tests exist for the story's functionality:
            ```bash
            # Run pytest for relevant tests
            python -m pytest <test_file> -v --tb=short 2>&1 || true
            ```

            ### 2d. Make Review Decision

            For each story, decide:
            - **PASS**: No significant issues, ready for verification
            - **FAIL**: Issues found that need attention

            ## Step 3: Update Story Status

            ```python
            python3 << 'UPDATE_SCRIPT'
            import sqlite3
            import json
            from datetime import datetime

            conn = sqlite3.connect('.claude/data/story-tree.db')
            conn.row_factory = sqlite3.Row

            # This script template - Claude will fill in REVIEW_RESULTS
            # Format: [{"id": "1.2.3", "decision": "PASS|FAIL", "reason": "..."}]
            REVIEW_RESULTS = []  # Claude replaces this with actual results

            passed = []
            failed = []

            for result in REVIEW_RESULTS:
                story_id = result['id']
                decision = result['decision']
                reason = result.get('reason', '')

                if decision == 'PASS':
                    # Transition to verifying
                    conn.execute("""
                        UPDATE story_nodes
                        SET stage = 'verifying',
                            notes = COALESCE(notes || char(10), '') ||
                                    'REVIEW PASSED: ' || ? || ' ' || datetime('now'),
                            updated_at = datetime('now')
                        WHERE id = ?
                    """, (reason, story_id))
                    passed.append({'id': story_id, 'reason': reason})
                else:
                    # Mark as broken
                    conn.execute("""
                        UPDATE story_nodes
                        SET hold_reason = 'broken',
                            notes = COALESCE(notes || char(10), '') ||
                                    'REVIEW FAILED: ' || ? || ' ' || datetime('now'),
                            updated_at = datetime('now')
                        WHERE id = ?
                    """, (reason, story_id))
                    failed.append({'id': story_id, 'reason': reason})

            conn.commit()

            print("=== Story Review Complete ===")
            print(f"Passed: {len(passed)} story(ies) → verifying")
            print(f"Failed: {len(failed)} story(ies) → broken")
            print("")
            if passed:
                print("Passed reviews:")
                for p in passed:
                    print(f"  ✓ {p['id']}: {p['reason'][:60]}...")
            if failed:
                print("Failed reviews:")
                for f in failed:
                    print(f"  ✗ {f['id']}: {f['reason'][:60]}...")

            print(json.dumps({'passed': passed, 'failed': failed}, indent=2))
            conn.close()
            UPDATE_SCRIPT
            ```

            **IMPORTANT**: Replace the `REVIEW_RESULTS = []` line with actual review results
            based on your analysis. Example:
            ```python
            REVIEW_RESULTS = [
                {"id": "1.3.6", "decision": "PASS", "reason": "Code review passed, no issues found"},
                {"id": "1.5.6", "decision": "FAIL", "reason": "Tests failing, needs fixes"}
            ]
            ```

            ## Step 4: Git Operations

            After reviewing stories:
            ```bash
            git checkout main && git pull origin main
            git add -A
            git diff --cached --quiet || git commit -m "ci: review stories $(date -u +'%Y-%m-%d')"
            git push origin main
            ```

            **CRITICAL**: Push changes before exiting.

            ## Constraints
            - Process all eligible reviewing stories in one run
            - 30-minute timeout (review takes longer than simple transitions)
            - Be thorough but decisive - don't leave stories in limbo

          # Tool permissions for file operations, database access, git, and testing
          # Using Opus 4.5 for code review - better judgment on deferrable vs blocking issues
          claude_args: |
            --allowedTools "Task,Read,Write,Edit,Glob,Grep,Bash(git:*),Bash(python:*),Bash(python3:*),Bash(sqlite3:*),Bash(pytest:*),Bash(pip:*),BashOutput,Skill,SlashCommand,TodoWrite"
            --model claude-opus-4-5-20251101
            --max-turns 50

      - name: Report Token Usage
        if: always()
        run: |
          echo "## Token Usage Report" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          EXEC_FILE="${{ steps.claude.outputs.execution_file }}"
          if [ -f "$EXEC_FILE" ]; then
            # Determine file format (JSONL vs JSON array) and extract data
            if jq -e 'type == "array"' "$EXEC_FILE" > /dev/null 2>&1; then
              # JSON array format
              INPUT_TOKENS=$(jq '[.[] | select(.message?.usage?) | .message.usage.input_tokens // 0] | add // 0' "$EXEC_FILE")
              OUTPUT_TOKENS=$(jq '[.[] | select(.message?.usage?) | .message.usage.output_tokens // 0] | add // 0' "$EXEC_FILE")
              TOTAL_COST=$(jq '[.[] | select(.type == "result")] | last | .total_cost_usd // .cost_usd // "N/A"' "$EXEC_FILE" | tr -d '"')
            else
              # JSONL format
              INPUT_TOKENS=$(grep -o '"input_tokens":[0-9]*' "$EXEC_FILE" | cut -d: -f2 | awk '{s+=$1} END {print s+0}')
              OUTPUT_TOKENS=$(grep -o '"output_tokens":[0-9]*' "$EXEC_FILE" | cut -d: -f2 | awk '{s+=$1} END {print s+0}')
              RESULT=$(grep '"type":"result"' "$EXEC_FILE" | tail -1)
              TOTAL_COST=$(echo "$RESULT" | jq -r '.total_cost_usd // .cost_usd // "N/A"' 2>/dev/null || echo "N/A")
            fi

            # Validate we got numeric values
            if ! [[ "$INPUT_TOKENS" =~ ^[0-9]+$ ]]; then INPUT_TOKENS=0; fi
            if ! [[ "$OUTPUT_TOKENS" =~ ^[0-9]+$ ]]; then OUTPUT_TOKENS=0; fi

            echo "| Metric | Value |" >> $GITHUB_STEP_SUMMARY
            echo "|--------|-------|" >> $GITHUB_STEP_SUMMARY
            echo "| Input Tokens | $INPUT_TOKENS |" >> $GITHUB_STEP_SUMMARY
            echo "| Output Tokens | $OUTPUT_TOKENS |" >> $GITHUB_STEP_SUMMARY
            echo "| Total Cost | \$$TOTAL_COST |" >> $GITHUB_STEP_SUMMARY
          else
            echo "⚠️ Execution file not found" >> $GITHUB_STEP_SUMMARY
          fi
