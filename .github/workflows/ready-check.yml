name: Daily Ready Check

# Run at 2:20 AM PST (10:20 UTC) every day - FIRST in DRAIN phase
# Checks implemented stories for integration readiness and advances to 'ready' stage
on:
  # schedule disabled - manual trigger only
  workflow_dispatch:

concurrency:
  group: daily-ready-check
  cancel-in-progress: false

permissions:
  contents: write
  issues: write
  pull-requests: write
  id-token: write

jobs:
  ready-check:
    runs-on: ubuntu-latest
    timeout-minutes: 30

    steps:
      - name: Checkout repository
        uses: actions/checkout@v5
        with:
          fetch-depth: 0  # Full history for git operations

      - name: Run Claude Code to check implemented stories
        id: claude
        uses: anthropics/claude-code-action@v1
        with:
          # GitHub token for repository operations (required for scheduled workflows)
          github_token: ${{ secrets.GITHUB_TOKEN }}

          # Use OAuth token for Max subscription
          claude_code_oauth_token: ${{ secrets.CLAUDE_CODE_OAUTH_TOKEN }}

          # Show full output for debugging
          show_full_output: true

          # Direct prompt mode for scheduled automation (CI-optimized)
          # Transition: implemented (no hold) → ready (pass) or implemented (broken)
          prompt: |
            MODE: Daily Ready Check (CI - fully autonomous)

            This workflow verifies that implemented stories are ready for release.
            Stories in 'implemented' stage have been verified and need a final
            integration check before being marked as 'ready' for deployment.

            ## Step 1: Find Stories Ready for Integration Check

            Query implemented stories without holds:

            ```python
            python3 << 'QUERY_SCRIPT'
            import sqlite3
            import json

            conn = sqlite3.connect('.claude/data/story-tree.db')
            conn.row_factory = sqlite3.Row

            # Find all implemented stories without holds
            stories = conn.execute("""
                SELECT id, title, description, notes, project_path
                FROM story_nodes
                WHERE stage = 'implemented'
                  AND hold_reason IS NULL
                  AND disposition IS NULL
                ORDER BY updated_at ASC
            """).fetchall()

            print(f"Found {len(stories)} story(ies) ready for integration check:")
            for s in stories:
                print(f"  - {s['id']}: {s['title'][:60]}...")

            result = {
                'count': len(stories),
                'stories': [
                    {
                        'id': s['id'],
                        'title': s['title'],
                        'description': s['description'],
                        'project_path': s['project_path'],
                        'notes': s['notes']
                    } for s in stories
                ]
            }
            print(json.dumps(result, indent=2))
            conn.close()
            QUERY_SCRIPT
            ```

            If count is 0, output "✓ No stories ready for integration check" and exit successfully.

            ## Step 2: Perform Integration Check

            For each story found, perform integration verification:

            ### 2a. Check Build Status

            Verify the application builds without errors:

            ```bash
            # For Python projects, check imports and syntax
            python3 -m py_compile src/syncopaid/*.py 2>&1 || echo "BUILD_WARNING"
            ```

            ### 2b. Run Full Test Suite (if tests exist)

            ```bash
            # Run pytest if available
            python -m pytest tests/ -v --tb=short 2>&1 || echo "TESTS_WARNING"
            ```

            ### 2c. Check for Conflicts with Other Stories

            Verify no merge conflicts or overlapping changes exist:

            ```bash
            git status --porcelain
            ```

            ### Integration Decision Matrix

            | Check | Result | Action |
            |-------|--------|--------|
            | Build + Tests pass | All OK | → `ready` |
            | Build fails | Error | → `implemented` with `hold_reason='broken'` |
            | Tests fail | Error | → `implemented` with `hold_reason='broken'` |
            | Pending conflicts | Warning | → `implemented` with `hold_reason='pending'` |

            ## Step 3: Update Story Status

            ```python
            python3 << 'UPDATE_SCRIPT'
            import sqlite3
            import json
            from datetime import datetime

            conn = sqlite3.connect('.claude/data/story-tree.db')
            conn.row_factory = sqlite3.Row

            # Claude fills in INTEGRATION_RESULTS based on analysis
            # Format: [{"id": "1.2.3", "decision": "PASS|FAIL|PENDING", "reason": "..."}]
            INTEGRATION_RESULTS = []  # Claude replaces this with actual results

            ready = []
            broken = []
            pending = []

            for result in INTEGRATION_RESULTS:
                story_id = result['id']
                decision = result['decision']
                reason = result.get('reason', '')

                if decision == 'PASS':
                    # Transition to ready
                    conn.execute("""
                        UPDATE story_nodes
                        SET stage = 'ready',
                            notes = COALESCE(notes || char(10), '') ||
                                    'READY: ' || ? || ' ' || datetime('now'),
                            updated_at = datetime('now')
                        WHERE id = ?
                    """, (reason, story_id))
                    ready.append({'id': story_id, 'reason': reason})
                elif decision == 'PENDING':
                    # Mark as pending review
                    conn.execute("""
                        UPDATE story_nodes
                        SET hold_reason = 'pending',
                            notes = COALESCE(notes || char(10), '') ||
                                    'INTEGRATION PENDING: ' || ? || ' ' || datetime('now'),
                            updated_at = datetime('now')
                        WHERE id = ?
                    """, (reason, story_id))
                    pending.append({'id': story_id, 'reason': reason})
                else:
                    # Mark as broken
                    conn.execute("""
                        UPDATE story_nodes
                        SET hold_reason = 'broken',
                            notes = COALESCE(notes || char(10), '') ||
                                    'INTEGRATION FAILED: ' || ? || ' ' || datetime('now'),
                            updated_at = datetime('now')
                        WHERE id = ?
                    """, (reason, story_id))
                    broken.append({'id': story_id, 'reason': reason})

            conn.commit()

            print("=== Integration Check Complete ===")
            print(f"Ready: {len(ready)} story(ies) → ready")
            print(f"Pending: {len(pending)} story(ies) → pending review")
            print(f"Broken: {len(broken)} story(ies) → broken")
            print("")
            if ready:
                print("Ready for release:")
                for r in ready:
                    print(f"  ✓ {r['id']}: {r['reason'][:60]}...")
            if pending:
                print("Needs human review:")
                for p in pending:
                    print(f"  ⚠ {p['id']}: {p['reason'][:60]}...")
            if broken:
                print("Failed integration:")
                for b in broken:
                    print(f"  ✗ {b['id']}: {b['reason'][:60]}...")

            print(json.dumps({'ready': ready, 'pending': pending, 'broken': broken}, indent=2))
            conn.close()
            UPDATE_SCRIPT
            ```

            **IMPORTANT**: Replace the `INTEGRATION_RESULTS = []` line with actual results
            based on your analysis. Example:
            ```python
            INTEGRATION_RESULTS = [
                {"id": "1.2.3", "decision": "PASS", "reason": "Build passes, all tests pass"},
                {"id": "1.4.5", "decision": "FAIL", "reason": "Build fails: syntax error in module"}
            ]
            ```

            ## Step 4: Git Operations

            After checking stories:
            ```bash
            git checkout main && git pull origin main
            git add -A
            git diff --cached --quiet || git commit -m "ci: ready-check $(date -u +'%Y-%m-%d')"
            git push origin main
            ```

            **CRITICAL**: Push changes before exiting.

            ## Constraints
            - Process all eligible implemented stories in one run
            - 30-minute timeout (integration checks are lightweight)
            - Focus on verifying stories work together, not individual functionality
            - Document specific integration results in the notes

          # Tool permissions for file operations, database access, git, and testing
          claude_args: |
            --allowedTools "Task,Read,Write,Edit,Glob,Grep,Bash(git:*),Bash(python:*),Bash(python3:*),Bash(sqlite3:*),Bash(pytest:*),Bash(npm:*),Bash(pip:*),BashOutput,Skill,SlashCommand,TodoWrite"
            --model claude-sonnet-4-5-20250929
            --max-turns 50

      - name: Report Token Usage
        if: always()
        run: |
          echo "## Token Usage Report" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          EXEC_FILE="${{ steps.claude.outputs.execution_file }}"
          if [ -f "$EXEC_FILE" ]; then
            # Determine file format (JSONL vs JSON array) and extract data
            if jq -e 'type == "array"' "$EXEC_FILE" > /dev/null 2>&1; then
              # JSON array format
              INPUT_TOKENS=$(jq '[.[] | select(.message?.usage?) | .message.usage.input_tokens // 0] | add // 0' "$EXEC_FILE")
              OUTPUT_TOKENS=$(jq '[.[] | select(.message?.usage?) | .message.usage.output_tokens // 0] | add // 0' "$EXEC_FILE")
              TOTAL_COST=$(jq '[.[] | select(.type == "result")] | last | .total_cost_usd // .cost_usd // "N/A"' "$EXEC_FILE" | tr -d '"')
            else
              # JSONL format
              INPUT_TOKENS=$(grep -o '"input_tokens":[0-9]*' "$EXEC_FILE" | cut -d: -f2 | awk '{s+=$1} END {print s+0}')
              OUTPUT_TOKENS=$(grep -o '"output_tokens":[0-9]*' "$EXEC_FILE" | cut -d: -f2 | awk '{s+=$1} END {print s+0}')
              RESULT=$(grep '"type":"result"' "$EXEC_FILE" | tail -1)
              TOTAL_COST=$(echo "$RESULT" | jq -r '.total_cost_usd // .cost_usd // "N/A"' 2>/dev/null || echo "N/A")
            fi

            # Validate we got numeric values
            if ! [[ "$INPUT_TOKENS" =~ ^[0-9]+$ ]]; then INPUT_TOKENS=0; fi
            if ! [[ "$OUTPUT_TOKENS" =~ ^[0-9]+$ ]]; then OUTPUT_TOKENS=0; fi

            echo "| Metric | Value |" >> $GITHUB_STEP_SUMMARY
            echo "|--------|-------|" >> $GITHUB_STEP_SUMMARY
            echo "| Input Tokens | $INPUT_TOKENS |" >> $GITHUB_STEP_SUMMARY
            echo "| Output Tokens | $OUTPUT_TOKENS |" >> $GITHUB_STEP_SUMMARY
            echo "| Total Cost | \$$TOTAL_COST |" >> $GITHUB_STEP_SUMMARY
          else
            echo "Execution file not found" >> $GITHUB_STEP_SUMMARY
          fi
