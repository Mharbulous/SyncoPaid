name: Execute Planned Story

# Run every 20 minutes for intensive story execution
on:
  schedule:
    - cron: '*/20 * * * *'
  workflow_dispatch:

concurrency:
  group: daily-story-execution
  cancel-in-progress: false

permissions:
  contents: write
  issues: write
  pull-requests: write
  id-token: write

jobs:
  execute-stories:
    runs-on: ubuntu-latest
    timeout-minutes: 60  # Explicit job timeout

    steps:
      - name: Checkout repository
        uses: actions/checkout@v5
        with:
          fetch-depth: 0  # Full history for git operations

      - name: Run Claude Code to execute stories
        id: claude
        uses: anthropics/claude-code-action@v1
        with:
          # GitHub token for repository operations (required for scheduled workflows)
          github_token: ${{ secrets.GITHUB_TOKEN }}

          # Use OAuth token for Max subscription
          claude_code_oauth_token: ${{ secrets.CLAUDE_CODE_OAUTH_TOKEN }}

          # Show full output for debugging
          show_full_output: true

          # Direct prompt mode for scheduled automation (CI-optimized)
          prompt: |
            MODE: Daily Story Execution (CI - fully autonomous)

            ## Step 1: Early Exit Check

            First, check if there are plan files available to execute:
            ```python
            python -c "
            import os, re
            plans_dir = '.claude/data/plans'
            pattern = re.compile(r'^(\d{3})([A-Z])?_.+\.md$')
            count = sum(1 for f in os.listdir(plans_dir) if pattern.match(f))
            print(f'Plan files available: {count}')
            "
            ```

            If count is 0, output "No plan files available for execution" and exit successfully.

            ## Step 2: Execute Plan (if plan files exist)

            Use the story-execution skill (CI mode auto-detected):
            ```
            Skill(skill="story-execution")
            ```

            Follow the skill workflow to:
            - Select the earliest sequence-numbered plan file from .claude/data/plans/
            - Plan files use pattern: NNN[A-Z]?_slug.md (e.g., 001_feature.md, 003A_subplan.md)
            - Execute only ONE plan file per run (even if 003A, 003B exist, only execute 003A)
            - Review plan critically (CI mode: classify issues as blocking or deferrable)
            - Execute tasks in batches of 3 with TDD cycles (RED-GREEN-COMMIT)
            - Archive completed plan to .claude/data/executed/
            - Update story status if Story ID found in plan:
              - If blocking issues: set hold_reason='paused', do not implement
              - If deferrable issues: execute, set stage='reviewing'
              - If no issues: execute, set stage='verifying'

            ## Step 3: Git Operations

            After executing the plan:
            ```bash
            git checkout main && git pull origin main
            git add -A
            git diff --cached --quiet || git commit -m "ci: execute plan $(date -u +'%Y-%m-%d')"
            git push origin main
            ```

            **CRITICAL**: Push changes before exiting.

            ## Constraints
            - Execute only 1 plan file per run
            - 60-minute timeout (execution takes longer than planning)

          # Tool permissions for file operations, database access, git, and testing
          claude_args: |
            --allowedTools "Task,Read,Write,Edit,Glob,Grep,Bash(git:*),Bash(python:*),Bash(python3:*),Bash(sqlite3:*),Bash(pytest:*),Bash(npm:*),Bash(pip:*),BashOutput,Skill,SlashCommand,TodoWrite"
            --model claude-sonnet-4-5-20250929
            --max-turns 100

      - name: Post Results to Story Issue
        if: always()
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          echo "## Posting Results to Story Issue" >> $GITHUB_STEP_SUMMARY

          # Find the most recently modified file in executed/ directory
          EXECUTED_DIR=".claude/data/executed"
          if [ ! -d "$EXECUTED_DIR" ]; then
            echo "No executed directory found, skipping issue update" >> $GITHUB_STEP_SUMMARY
            exit 0
          fi

          # Get the most recently modified plan file (by git, looking at the last commit)
          LATEST_PLAN=$(git diff --name-only HEAD~1 HEAD -- "$EXECUTED_DIR" 2>/dev/null | head -1)

          # If no file found via git diff, try finding most recent by modification time
          if [ -z "$LATEST_PLAN" ] || [ ! -f "$LATEST_PLAN" ]; then
            LATEST_PLAN=$(ls -t "$EXECUTED_DIR"/*.md 2>/dev/null | head -1)
          fi

          if [ -z "$LATEST_PLAN" ] || [ ! -f "$LATEST_PLAN" ]; then
            echo "No executed plan file found, skipping issue update" >> $GITHUB_STEP_SUMMARY
            exit 0
          fi

          echo "Found executed plan: $LATEST_PLAN" >> $GITHUB_STEP_SUMMARY

          # Extract the base sequence number from filename (e.g., "006" from "006A_something.md")
          PLAN_FILENAME=$(basename "$LATEST_PLAN")
          BASE_SEQ=$(echo "$PLAN_FILENAME" | grep -oP '^\d+')
          SUB_PLAN_ID=$(echo "$PLAN_FILENAME" | grep -oP '^\d+\K[A-Z]?' | head -1)

          echo "Plan sequence: ${BASE_SEQ}${SUB_PLAN_ID}" >> $GITHUB_STEP_SUMMARY

          # Extract Story ID from the plan file (format: **Story ID:** X.Y | ...)
          STORY_ID=$(grep -oP '\*\*Story ID:\*\*\s*\K[0-9]+(\.[0-9]+)*' "$LATEST_PLAN" | head -1)

          # If no Story ID in current plan, search sibling plans with same base sequence
          # This handles decomposed plans (006A, 006B, 006C) that share a parent story
          if [ -z "$STORY_ID" ] && [ -n "$BASE_SEQ" ]; then
            echo "No Story ID in current plan, searching sibling plans..." >> $GITHUB_STEP_SUMMARY

            # Search in both executed and plans directories for any file with same base sequence
            for SEARCH_DIR in ".claude/data/executed" ".claude/data/plans"; do
              if [ -d "$SEARCH_DIR" ]; then
                for SIBLING in "$SEARCH_DIR"/${BASE_SEQ}*.md "$SEARCH_DIR"/${BASE_SEQ}[A-Z]*.md; do
                  if [ -f "$SIBLING" ]; then
                    FOUND_ID=$(grep -oP '\*\*Story ID:\*\*\s*\K[0-9]+(\.[0-9]+)*' "$SIBLING" 2>/dev/null | head -1)
                    if [ -n "$FOUND_ID" ]; then
                      STORY_ID="$FOUND_ID"
                      echo "Found Story ID $STORY_ID in sibling: $(basename "$SIBLING")" >> $GITHUB_STEP_SUMMARY
                      break 2
                    fi
                  fi
                done
              fi
            done
          fi

          if [ -z "$STORY_ID" ]; then
            echo "No Story ID found in plan or siblings, skipping issue update" >> $GITHUB_STEP_SUMMARY
            exit 0
          fi

          # Get story title from story-tree database using Story ID
          STORY_TITLE=""
          if command -v python3 &> /dev/null && [ -f ".claude/data/story-tree.db" ]; then
            STORY_TITLE=$(python3 -c "
import sqlite3
try:
    conn = sqlite3.connect('.claude/data/story-tree.db')
    cursor = conn.execute('SELECT title FROM story_nodes WHERE id = ?', ('$STORY_ID',))
    row = cursor.fetchone()
    if row:
        print(row[0])
except:
    pass
" 2>/dev/null)
          fi

          # Fallback: extract title from plan markdown header
          if [ -z "$STORY_TITLE" ]; then
            STORY_TITLE=$(grep -m1 '^# ' "$LATEST_PLAN" | sed 's/^# //' | sed 's/^[0-9A-Z]*: //')
          fi

          # Final fallback: use plan filename
          if [ -z "$STORY_TITLE" ]; then
            STORY_TITLE=$(basename "$LATEST_PLAN" .md | sed 's/^[0-9A-Z]*_//' | tr '-' ' ')
          fi

          ISSUE_TITLE="${STORY_ID} - ${STORY_TITLE}"
          echo "Story Issue Title: $ISSUE_TITLE" >> $GITHUB_STEP_SUMMARY

          # Check if issue already exists
          ISSUE_NUMBER=$(gh issue list --state all --search "\"${ISSUE_TITLE}\" in:title" --json number,title --jq ".[] | select(.title == \"${ISSUE_TITLE}\") | .number" | head -1)

          if [ -z "$ISSUE_NUMBER" ]; then
            echo "Creating new issue: $ISSUE_TITLE" >> $GITHUB_STEP_SUMMARY
            ISSUE_NUMBER=$(gh issue create \
              --title "$ISSUE_TITLE" \
              --body "Tracking issue for story node **${STORY_ID}**

## Description
${STORY_TITLE}

---
*This issue was automatically created by the execute-stories workflow to track CI execution results.*" \
              --label "story-tracking" 2>/dev/null | grep -oP 'issues/\K[0-9]+' || echo "")

            # If label doesn't exist, try without it
            if [ -z "$ISSUE_NUMBER" ]; then
              ISSUE_NUMBER=$(gh issue create \
                --title "$ISSUE_TITLE" \
                --body "Tracking issue for story node **${STORY_ID}**

## Description
${STORY_TITLE}

---
*This issue was automatically created by the execute-stories workflow to track CI execution results.*" \
                | grep -oP 'issues/\K[0-9]+' || echo "")
            fi

            if [ -n "$ISSUE_NUMBER" ]; then
              echo "Created issue #${ISSUE_NUMBER}" >> $GITHUB_STEP_SUMMARY
            else
              echo "Failed to create issue" >> $GITHUB_STEP_SUMMARY
              exit 0
            fi
          else
            echo "Found existing issue #${ISSUE_NUMBER}" >> $GITHUB_STEP_SUMMARY
          fi

          # Determine job result status
          JOB_STATUS="${{ job.status }}"
          if [ "$JOB_STATUS" = "success" ]; then
            STATUS_EMOJI="✅"
            STATUS_TEXT="Success"
          elif [ "$JOB_STATUS" = "failure" ]; then
            STATUS_EMOJI="❌"
            STATUS_TEXT="Failed"
          else
            STATUS_EMOJI="⚠️"
            STATUS_TEXT="$JOB_STATUS"
          fi

          # Build the result comment
          RUN_URL="${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}"
          TIMESTAMP=$(date -u +"%Y-%m-%d %H:%M:%S UTC")
          PLAN_FILENAME=$(basename "$LATEST_PLAN")

          COMMENT_BODY="## ${STATUS_EMOJI} Execution Result: ${STATUS_TEXT}

**Plan Executed:** \`${PLAN_FILENAME}\`
**Timestamp:** ${TIMESTAMP}
**Workflow Run:** [View Details](${RUN_URL})

### Summary
Story execution completed with status: **${STATUS_TEXT}**

---
*Posted automatically by [execute-stories workflow](${RUN_URL})*"

          # Post comment to the issue
          echo "$COMMENT_BODY" | gh issue comment "$ISSUE_NUMBER" --body-file -

          if [ $? -eq 0 ]; then
            echo "Posted results to issue #${ISSUE_NUMBER}" >> $GITHUB_STEP_SUMMARY
          else
            echo "Failed to post comment to issue #${ISSUE_NUMBER}" >> $GITHUB_STEP_SUMMARY
          fi

      - name: Report Token Usage
        if: always()
        run: |
          echo "## Token Usage Report" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          EXEC_FILE="${{ steps.claude.outputs.execution_file }}"
          if [ -f "$EXEC_FILE" ]; then
            # Debug: Show file format
            echo "::debug::Execution file size: $(wc -c < "$EXEC_FILE") bytes"

            # Determine file format (JSONL vs JSON array) and extract data
            # Try to parse as JSON array first, fall back to JSONL
            if jq -e 'type == "array"' "$EXEC_FILE" > /dev/null 2>&1; then
              # JSON array format - sum usage from all messages with message.usage
              INPUT_TOKENS=$(jq '[.[] | select(.message?.usage?) | .message.usage.input_tokens // 0] | add // 0' "$EXEC_FILE")
              OUTPUT_TOKENS=$(jq '[.[] | select(.message?.usage?) | .message.usage.output_tokens // 0] | add // 0' "$EXEC_FILE")
              CACHE_CREATION=$(jq '[.[] | select(.message?.usage?) | .message.usage.cache_creation_input_tokens // 0] | add // 0' "$EXEC_FILE")
              CACHE_READ=$(jq '[.[] | select(.message?.usage?) | .message.usage.cache_read_input_tokens // 0] | add // 0' "$EXEC_FILE")
              # Get cost and duration from result entry
              TOTAL_COST=$(jq '[.[] | select(.type == "result")] | last | .total_cost_usd // .cost_usd // "N/A"' "$EXEC_FILE" | tr -d '"')
              DURATION_MS=$(jq '[.[] | select(.type == "result")] | last | .duration_ms // "N/A"' "$EXEC_FILE" | tr -d '"')
            else
              # JSONL format - use grep + jq
              INPUT_TOKENS=$(grep -o '"input_tokens":[0-9]*' "$EXEC_FILE" | cut -d: -f2 | awk '{s+=$1} END {print s+0}')
              OUTPUT_TOKENS=$(grep -o '"output_tokens":[0-9]*' "$EXEC_FILE" | cut -d: -f2 | awk '{s+=$1} END {print s+0}')
              CACHE_CREATION=$(grep -o '"cache_creation_input_tokens":[0-9]*' "$EXEC_FILE" | cut -d: -f2 | awk '{s+=$1} END {print s+0}')
              CACHE_READ=$(grep -o '"cache_read_input_tokens":[0-9]*' "$EXEC_FILE" | cut -d: -f2 | awk '{s+=$1} END {print s+0}')
              RESULT=$(grep '"type":"result"' "$EXEC_FILE" | tail -1)
              if [ -n "$RESULT" ]; then
                TOTAL_COST=$(echo "$RESULT" | jq -r '.total_cost_usd // .cost_usd // "N/A"')
                DURATION_MS=$(echo "$RESULT" | jq -r '.duration_ms // "N/A"')
              else
                TOTAL_COST="N/A"
                DURATION_MS="N/A"
              fi
            fi

            # Validate we got numeric values
            if ! [[ "$INPUT_TOKENS" =~ ^[0-9]+$ ]]; then INPUT_TOKENS=0; fi
            if ! [[ "$OUTPUT_TOKENS" =~ ^[0-9]+$ ]]; then OUTPUT_TOKENS=0; fi
            if ! [[ "$CACHE_CREATION" =~ ^[0-9]+$ ]]; then CACHE_CREATION=0; fi
            if ! [[ "$CACHE_READ" =~ ^[0-9]+$ ]]; then CACHE_READ=0; fi

            # Calculate total tokens
            if [ "$INPUT_TOKENS" -gt 0 ] || [ "$OUTPUT_TOKENS" -gt 0 ]; then
              TOTAL_TOKENS=$((INPUT_TOKENS + OUTPUT_TOKENS))
            else
              TOTAL_TOKENS="N/A"
            fi

            # Format duration in seconds
            if [[ "$DURATION_MS" =~ ^[0-9]+$ ]]; then
              DURATION_S=$(echo "scale=1; $DURATION_MS / 1000" | bc)
            else
              DURATION_S="N/A"
            fi

            echo "| Metric | Value |" >> $GITHUB_STEP_SUMMARY
            echo "|--------|-------|" >> $GITHUB_STEP_SUMMARY
            echo "| Input Tokens | $INPUT_TOKENS |" >> $GITHUB_STEP_SUMMARY
            echo "| Output Tokens | $OUTPUT_TOKENS |" >> $GITHUB_STEP_SUMMARY
            echo "| Cache Creation Tokens | $CACHE_CREATION |" >> $GITHUB_STEP_SUMMARY
            echo "| Cache Read Tokens | $CACHE_READ |" >> $GITHUB_STEP_SUMMARY
            echo "| **Total Tokens** | **$TOTAL_TOKENS** |" >> $GITHUB_STEP_SUMMARY
            echo "| Total Cost | \$$TOTAL_COST |" >> $GITHUB_STEP_SUMMARY
            echo "| Duration | ${DURATION_S}s |" >> $GITHUB_STEP_SUMMARY
          else
            echo "⚠️ Execution file not found: $EXEC_FILE" >> $GITHUB_STEP_SUMMARY
          fi
